{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/amirtesh/Downloads/Computers/Python/MachineLearning/Pytorch/Convolutional neural networks/Vehicles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.ImageFolder(os.path.join(path,'train'),transform=train_transform)\n",
    "test_data=datasets.ImageFolder(os.path.join(path,'test'),transform=test_transform)  \n",
    "val_data=datasets.ImageFolder(os.path.join(path,'val'),transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 3542\n",
      "Test data: 1777\n",
      "Validation data: 583\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data: {len(train_data)}')\n",
    "print(f'Test data: {len(test_data)}')   \n",
    "print(f'Validation data: {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    model.eval() \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            test_pred_logits = model(X)\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model:torch.nn.Module,\n",
    "          train_dataloader:torch.utils.data.DataLoader,\n",
    "          test_dataloader:torch.utils.data.DataLoader,\n",
    "          optimizer:torch.optim.Optimizer,\n",
    "          loss_fn:torch.nn.Module,\n",
    "          epochs:int):\n",
    "    \n",
    "    results={'train_loss':[],\n",
    "             'train_acc':[],\n",
    "             'test_loss':[],\n",
    "             'test_acc':[]}\n",
    "    \n",
    "    for i in tqdm(range(epochs)):\n",
    "        train_loss,train_acc=train_step(model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer)\n",
    "        test_loss,test_acc=test_step(model=model,\n",
    "                                     dataloader=test_dataloader,\n",
    "                                     loss_fn=loss_fn)\n",
    "        print(f'Epoch {i} | Train loss: {train_loss:.4f},Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f},Test acc: {test_acc:.4f}')\n",
    "        results['train_loss'].append(train_loss)\n",
    "        results['train_acc'].append(train_acc)\n",
    "        results['test_loss'].append(test_loss)\n",
    "        results['test_acc'].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)\n",
    "train_dl=DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_dl=DataLoader(test_data,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane', 'cruise ship', 'helicopter', 'motorbike', 'truck']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane', 'cruise ship', 'helicopter', 'motorbike', 'truck']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.classes==train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Conv2d(32,64,3,1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64,128,3,1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Conv2d(128,128,3,1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(25088,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128,len(class_names))\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        return F.log_softmax(self.fc(self.conv(X)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)\n",
    "model1=Model1()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model1.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd=Model1()\n",
    "x=torch.ones((32,3,224,224))\n",
    "dd(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc760267a824f1295a872a2aa701697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss: 1.4050,Train acc: 0.4209 | Test loss: 1.2686,Test acc: 0.5262\n",
      "Epoch 1 | Train loss: 1.0202,Train acc: 0.5945 | Test loss: 1.1535,Test acc: 0.5344\n",
      "Epoch 2 | Train loss: 0.8497,Train acc: 0.6689 | Test loss: 1.1348,Test acc: 0.5674\n",
      "Epoch 3 | Train loss: 0.7734,Train acc: 0.7026 | Test loss: 0.7191,Test acc: 0.7184\n",
      "Epoch 4 | Train loss: 0.7133,Train acc: 0.7201 | Test loss: 0.7819,Test acc: 0.7034\n",
      "Epoch 5 | Train loss: 0.6464,Train acc: 0.7547 | Test loss: 0.6814,Test acc: 0.7334\n",
      "Epoch 6 | Train loss: 0.5934,Train acc: 0.7753 | Test loss: 0.7381,Test acc: 0.7257\n",
      "Epoch 7 | Train loss: 0.5659,Train acc: 0.7930 | Test loss: 0.5756,Test acc: 0.7760\n",
      "Epoch 8 | Train loss: 0.4980,Train acc: 0.8075 | Test loss: 0.5241,Test acc: 0.8036\n",
      "Epoch 9 | Train loss: 0.4515,Train acc: 0.8287 | Test loss: 0.4926,Test acc: 0.8254\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "n=10\n",
    "model_results=train(\n",
    "    model=model1,\n",
    "    train_dataloader=train_dl,\n",
    "    test_dataloader=test_dl,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=criterion,\n",
    "    epochs=n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct: 1473/1777 | Accuracy: 82.89251547552054\n"
     ]
    }
   ],
   "source": [
    "index=list(range(1777))\n",
    "\n",
    "c=0\n",
    "for i in index:\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        pred=model1(test_data[i][0].view(1,3,224,224)).argmax()\n",
    "\n",
    "    \n",
    "    if class_names[test_data[i][1]]==class_names[pred.item()]:\n",
    "        c+=1\n",
    "\n",
    "print(f'Number of correct: {c}/{len(test_data)} | Accuracy: {c*100/len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct: 491/583 | Accuracy: 84.21955403087479\n"
     ]
    }
   ],
   "source": [
    "index=list(range(583))\n",
    "\n",
    "c=0\n",
    "for i in index:\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        pred=model1(val_data[i][0].view(1,3,224,224)).argmax()\n",
    "\n",
    "    \n",
    "    if class_names[val_data[i][1]]==class_names[pred.item()]:\n",
    "        c+=1\n",
    "\n",
    "print(f'Number of correct: {c}/{len(val_data)} | Accuracy: {c*100/len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=models.resnet34(pretrained=True)\n",
    "model2.fc=None\n",
    "model2.fc=nn.Linear(512,len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model2.parameters(),lr=0.001)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec6a14fc20e4b7eb216d8a4226edac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss: 0.5032,Train acc: 0.8348 | Test loss: 0.5364,Test acc: 0.8019\n",
      "Epoch 1 | Train loss: 0.3025,Train acc: 0.9011 | Test loss: 0.2963,Test acc: 0.9038\n",
      "Epoch 2 | Train loss: 0.2048,Train acc: 0.9311 | Test loss: 0.3089,Test acc: 0.8991\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "n=3\n",
    "model2_results=train(\n",
    "    model=model2,\n",
    "    train_dataloader=train_dl,\n",
    "    test_dataloader=test_dl,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=criterion,\n",
    "    epochs=n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct: 1597/1777 | Accuracy: 89.87056837366347\n"
     ]
    }
   ],
   "source": [
    "index=list(range(1777))\n",
    "\n",
    "c=0\n",
    "for i in index:\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        pred=model2(test_data[i][0].view(1,3,224,224)).argmax()\n",
    "\n",
    "    \n",
    "    if class_names[test_data[i][1]]==class_names[pred.item()]:\n",
    "        c+=1\n",
    "\n",
    "print(f'Number of correct: {c}/{len(test_data)} | Accuracy: {c*100/len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct: 512/583 | Accuracy: 87.82161234991423\n"
     ]
    }
   ],
   "source": [
    "index=list(range(583))\n",
    "\n",
    "c=0\n",
    "for i in index:\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        pred=model2(val_data[i][0].view(1,3,224,224)).argmax()\n",
    "\n",
    "    \n",
    "    if class_names[val_data[i][1]]==class_names[pred.item()]:\n",
    "        c+=1\n",
    "\n",
    "print(f'Number of correct: {c}/{len(val_data)} | Accuracy: {c*100/len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
